<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大模型 on MMay`s Site</title>
        <link>https://example.com/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link>
        <description>Recent content in 大模型 on MMay`s Site</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Mon, 17 Jun 2024 11:19:47 +0800</lastBuildDate><atom:link href="https://example.com/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Llama F部署</title>
        <link>https://example.com/p/llama-f%E9%83%A8%E7%BD%B2/</link>
        <pubDate>Mon, 17 Jun 2024 11:19:47 +0800</pubDate>
        
        <guid>https://example.com/p/llama-f%E9%83%A8%E7%BD%B2/</guid>
        <description>&lt;h1 id=&#34;ascend部署流程&#34;&gt;Ascend部署流程&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;113
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;114
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;115
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;116
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;117
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;118
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;119
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;120
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;121
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;122
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;123
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;124
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;125
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;126
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;127
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;128
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;129
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;130
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;131
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;132
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;133
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;134
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;135
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;136
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;137
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 下载Obsutil工具&lt;/span&gt;
wget https://obs-community-intl.obs.ap-southeast-1.myhuaweicloud.com/obsutil/current/obsutil_linux_arm64.tar.gz

&lt;span class=&#34;c1&#34;&gt;# 解压Obsutil工具&lt;/span&gt;
tar -zxvf obsutil_linux_arm64.tar.gz

&lt;span class=&#34;c1&#34;&gt;# 进入Obsutil工具目录&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; obsutil_linux_arm64_5.5.12/

&lt;span class=&#34;c1&#34;&gt;# 配置Obsutil工具&lt;/span&gt;
./obsutil config -i&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;RY5N2COYIZMAHGKGNTLK -k&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;yHv2w8gDcNZBVf3XglM7qKADpu0qr8Y9O7Qa0Lwq -e&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;obs.syaicenter.com

&lt;span class=&#34;c1&#34;&gt;# 下载24.1.rc1版本的Ascend-HDK和CANN&lt;/span&gt;
./obsutil cp -r -f obs://lsh-infer/24.1.rc1/ ./

&lt;span class=&#34;c1&#34;&gt;# 进入下载的24.1.rc1目录&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; 24.1.rc1/

&lt;span class=&#34;c1&#34;&gt;# 给Ascend-HDK和CANN的文件设置执行权限&lt;/span&gt;
chmod +x ./Ascend-HDK-24.1.RC1/*
chmod +x ./CANN-8.0.RC1/*

&lt;span class=&#34;c1&#34;&gt;# 进入Ascend-HDK目录&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; Ascend-HDK-24.1.RC1/

&lt;span class=&#34;c1&#34;&gt;# 更新Ascend-HDK驱动&lt;/span&gt;
./Ascend-hdk-910-npu-driver_24.1.rc1_linux-aarch64.run --upgrade

&lt;span class=&#34;c1&#34;&gt;# 检查昇腾AI处理器状态&lt;/span&gt;
npu-smi info

&lt;span class=&#34;c1&#34;&gt;# 如果有进程占用昇腾AI处理器，杀掉这些进程&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;kill&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;151800&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;151802&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 检查昇腾AI处理器状态&lt;/span&gt;
npu-smi info

&lt;span class=&#34;c1&#34;&gt;# 强制杀掉进程&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;kill&lt;/span&gt; -9 &lt;span class=&#34;m&#34;&gt;151800&lt;/span&gt;
npu-smi info
&lt;span class=&#34;nb&#34;&gt;kill&lt;/span&gt; -9 &lt;span class=&#34;m&#34;&gt;151802&lt;/span&gt;
npu-smi info

&lt;span class=&#34;c1&#34;&gt;# 更新Ascend-HDK驱动&lt;/span&gt;
./Ascend-hdk-910-npu-driver_24.1.rc1_linux-aarch64.run --upgrade

&lt;span class=&#34;c1&#34;&gt;# 更新Ascend-HDK固件&lt;/span&gt;
./Ascend-hdk-910-npu-firmware_7.1.0.6.220.run --upgrade

&lt;span class=&#34;c1&#34;&gt;# 重启机器&lt;/span&gt;
reboot

&lt;span class=&#34;c1&#34;&gt;# 进入CANN目录&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; obsutil_linux_arm64_5.5.12/24.1.rc1/CANN-8.0.RC1/

&lt;span class=&#34;c1&#34;&gt;# 更新CANN工具包&lt;/span&gt;
./Ascend-cann-toolkit_8.0.RC1_linux-aarch64.run --upgrade

&lt;span class=&#34;c1&#34;&gt;# 安装CANN内核&lt;/span&gt;
./Ascend-cann-kernels-910_8.0.RC1_linux.run --install

&lt;span class=&#34;c1&#34;&gt;# 设置Ascend环境变量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; /usr/local/Ascend/ascend-toolkit/set_env.sh

&lt;span class=&#34;c1&#34;&gt;# 创建conda环境并激活&lt;/span&gt;
conda create -n torch2.1 &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.9 -y
conda activate torch2.1

&lt;span class=&#34;c1&#34;&gt;# 安装所需Python包&lt;/span&gt;
pip install wheel pyyaml typing_extensions numpy &lt;span class=&#34;nv&#34;&gt;protobuf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;3.20 sympy /usr/local/Ascend/ascend-toolkit/latest/lib64/te-*-py3-none-any.whl /usr/local/Ascend/ascend-toolkit/latest/lib64/hccl-*-py3-none-any.whl -i https://pypi.tuna.tsinghua.edu.cn/simple

&lt;span class=&#34;c1&#34;&gt;# 下载并安装torch和torch&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 下载torch和torchvision&lt;/span&gt;
wget https://download.pytorch.org/whl/cpu/torch-2.1.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl

&lt;span class=&#34;c1&#34;&gt;# 激活conda环境&lt;/span&gt;
conda activate torch2.1

&lt;span class=&#34;c1&#34;&gt;# 安装下载的torch&lt;/span&gt;
pip install torch-2.1.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl -i https://pypi.tuna.tsinghua.edu.cn/simple

&lt;span class=&#34;c1&#34;&gt;# 下载torch_npu&lt;/span&gt;
wget https://gitee.com/ascend/pytorch/releases/download/v6.0.rc1.1-pytorch2.1.0/torch_npu-2.1.0.post5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl

&lt;span class=&#34;c1&#34;&gt;# 安装torch_npu&lt;/span&gt;
pip install torch_npu-2.1.0.post5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl -i https://pypi.tuna.tsinghua.edu.cn/simple

&lt;span class=&#34;c1&#34;&gt;# 安装torchvision&lt;/span&gt;
pip install &lt;span class=&#34;nv&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;0.16.0 -i https://pypi.tuna.tsinghua.edu.cn/simple

&lt;span class=&#34;c1&#34;&gt;# 验证torch_npu安装是否成功&lt;/span&gt;
python -c &lt;span class=&#34;s2&#34;&gt;&amp;#34;import torch;import torch_npu;print(torch_npu.npu.is_available());x = torch.randn(2, 2).npu();y = torch.randn(2, 2).npu();z = x.mm(y);print(z)&amp;#34;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 设置Ascend环境变量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; /usr/local/Ascend/ascend-toolkit/set_env.sh

&lt;span class=&#34;c1&#34;&gt;# 再次验证torch_npu安装是否成功&lt;/span&gt;
python -c &lt;span class=&#34;s2&#34;&gt;&amp;#34;import torch;import torch_npu;print(torch_npu.npu.is_available());x = torch.randn(2, 2).npu();y = torch.randn(2, 2).npu();z = x.mm(y);print(z)&amp;#34;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 更新bashrc文件&lt;/span&gt;
vi ~/.bashrc
&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; ~/.bashrc

&lt;span class=&#34;c1&#34;&gt;# 克隆LLaMA-Factory仓库&lt;/span&gt;
git clone -b v0.8.1 https://github.com/hiyouga/LLaMA-Factory.git

&lt;span class=&#34;c1&#34;&gt;# 进入LLaMA-Factory目录&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; LLaMA-Factory/

&lt;span class=&#34;c1&#34;&gt;# 安装LLaMA-Factory所需的Python包&lt;/span&gt;
pip install -e &lt;span class=&#34;s2&#34;&gt;&amp;#34;.[torch,metrics]&amp;#34;&lt;/span&gt; -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install -r ./requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

&lt;span class=&#34;c1&#34;&gt;# 进入LLaMA-Factory目录&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; /home/LLaMA-Factory/

&lt;span class=&#34;c1&#34;&gt;# 安装modelscope&lt;/span&gt;
pip install modelscope -i https://pypi.tuna.tsinghua.edu.cn/simple

&lt;span class=&#34;c1&#34;&gt;# 设置MODELSCOPE_CACHE环境变量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;MODELSCOPE_CACHE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/home

&lt;span class=&#34;c1&#34;&gt;# 运行LLaMA-Factory&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;ASCEND_RT_VISIBLE_DEVICES&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; llamafactory-cli chat --model_name_or_path ../hub/AI-ModelScope/codegemma-7b-it/ --template gemma --do_sample False


&lt;span class=&#34;c1&#34;&gt;# 运行LLaMA-Factory API&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;ASCEND_RT_VISIBLE_DEVICES&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;API_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;29105&lt;/span&gt; llamafactory-cli api --model_name_or_path ../hub/AI-ModelScope/codegemma-7b-it/ --template gemma --do_sample False

&lt;span class=&#34;c1&#34;&gt;# 在后台以nohup方式运行LLaMA-Factory API，并将输出重定向到output.log文件&lt;/span&gt;
nohup &lt;span class=&#34;nv&#34;&gt;ASCEND_RT_VISIBLE_DEVICES&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;API_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;29105&lt;/span&gt; llamafactory-cli api --model_name_or_path ../hub/AI-ModelScope/codegemma-7b-it/ --template gemma --do_sample False &amp;gt; output.log 2&amp;gt;&lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 使用tail命令查看output.log文件的最新内容&lt;/span&gt;
tail -f output.log

&lt;span class=&#34;c1&#34;&gt;# 设置昇腾AI环境变量&lt;/span&gt;
hccn_tool -i &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; -gateway -g
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>QA问答</title>
        <link>https://example.com/p/qa%E9%97%AE%E7%AD%94/</link>
        <pubDate>Mon, 18 Mar 2024 09:50:58 +0800</pubDate>
        
        <guid>https://example.com/p/qa%E9%97%AE%E7%AD%94/</guid>
        <description>&lt;img src="https://example.com/p/qa%E9%97%AE%E7%AD%94/Orange.webp" alt="Featured image of post QA问答" /&gt;&lt;p&gt;Q:系统要有兜底回复
A:需求说明：兜底回复功能旨在确保所有收到的客户消息都能够得到及时且恰当的响应，即使在当前系统无法提供一个确切答案或是业务用户不在线的情况下。该功能应当能够识别出无法处理的咨询，并自动发送预设的标准答案，以保持客户的良好服务体验。
解决方案：当 RPA 机器人从企业微信群中抓取到客户的问题后，通过坐席系统调用知识库系统的 API 寻找需要回复的内容，如果未找到任何可以回复的内容，那么可以进行兜底回复，需要支持在坐席系统上配置兜底回复内容。实现细节：兜底回复配置,用户可自定义兜底回复的内容;响应机制配置:如果未查找到信息，通知到对应客户经理，比如客户经理 3 分钟内没有进行回复，那么触发兜底回复;应急人员配置:同一用户多次询问，应急通知人员回复&lt;/p&gt;
&lt;p&gt;Q:客户用企业微信发过来的语音能转文字
A:需求说明：对于客户发送的语音信息，也能够进行回复 解决方案：RPA 自动右键语音，选择转语音，并采集 使用企业微信接口获取音频文件，使用三方 NLP 接口进行提取 实现细节：RPA 进入会话，检查语音按钮，鼠标右键点击，选择转语音&lt;/p&gt;
&lt;p&gt;Q:业务用户能编排任务，任务策略，例如：加好友和回复任务之间的顺序等
A:需求说明：使其能够自主定义和管理各种任务（例如，加好友、发送回复等）的执行顺序和策略,防止某些极端情况比如：任务执行时间过长，重要的任务得不到执行等情况 解决方案：任务管理 实现细节：任务配置 可以设置客户经理的流程任务;任务编排 可以设置流程任务的优先级策略&lt;/p&gt;
&lt;p&gt;Q:支持调用其他系统的任务
A:需求说明：能够执行对其他系统操作（内部系统，资料库）的任务;解决方案：RPA;实现细节：RPA 流程开发:RPA 能够跨系统拾取，将多系统的执行操作组合成流程任务&lt;/p&gt;
&lt;p&gt;Q:需要列出每个用户的微信群
A:需求说明：能够获取客户经理各自添加的微信群;解决方案：企业微信 API-会话内容存档;实现细节：客群管理-会话存档:可以查看每个用户客群/客户的会话记录&lt;/p&gt;
&lt;p&gt;Q:能维护标签，例如：对应的人员，一个人可能有多标签，客群管理
A:需求说明：能够为客户经理各自添加的微信群添加标签;解决方案：客群管理-标签管理;实现细节：标签管理:可以对客群/客户添加标签，设置回复角色&lt;/p&gt;
&lt;p&gt;Q:支持统计任务，任务日志查询，任务问题追溯
A:需求说明：对执行的任务进行统计，支持查询，支持运行记录后台日志的查看;解决方案：任务管理;实现细节：审计日志记录:RPA 在执行任务中，记录运行日志及客群讯息：包括执行对象，任务类型，消息内容，信息来源，情感分析，执行状态，应答内容，RPA 结果反馈等信息;任务统计:可对执行的任务进行查询，可以自定义筛选条件，比如按照状态/任务类型&lt;/p&gt;
&lt;p&gt;Q:统计实时待回复的消息
A:需求说明：系统需要能够实时监测和统计待回复的消息以及来源。解决方案：任务管理;实现细节：审计日志记录:RPA在执行任务中，记录运行日志及客群讯息：包括执行对象，任务类型，消息内容，信息来源，情感分析，执行状态，应答内容，RPA结果反馈等信息;实时监控:可以查看到执行状态为待回复的任务详情,可以查看到执行状态为情感分析为负的任务详情&lt;/p&gt;
&lt;p&gt;Q:客户发送的消息支持关键词实时提示，包括投诉等
A:需求说明：系统需要能够实时监测和统计待回复的消息以及来源。解决方案：任务管理;实现细节：审计日志记录:RPA在执行任务中，记录运行日志及客群讯息：包括执行对象，任务类型，消息内容，信息来源，情感分析，执行状态，应答内容，RPA结果反馈等信息;实时监控:可以查看到执行状态为待回复的任务详情,可以查看到执行状态为情感分析为负的任务详情&lt;/p&gt;
&lt;p&gt;Q:统计执行结果，完成任务数量，触达了客户数量等。
A:需求说明：系统需要能够实时监测和统计待回复的消息以及来源。解决方案：任务管理;实现细节：审计日志记录:RPA在执行任务中，记录运行日志及客群讯息：包括执行对象，任务类型，消息内容，信息来源，情感分析，执行状态，应答内容，RPA结果反馈等信息;实时监控:可以查看到执行状态为待回复的任务详情,可以查看到执行状态为情感分析为负的任务详情&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
